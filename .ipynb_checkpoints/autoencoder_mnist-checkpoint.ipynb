{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d1b67dc7ee0f>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/givenone/morpheus/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 다운로드 합니다.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_RMSProp = 0.02\n",
    "learning_rate_GradientDescent = 0.5\n",
    "num_epochs = 100         # 반복횟수\n",
    "batch_size = 256          \n",
    "display_step = 1         # 몇 Step마다 log를 출력할지 결정합니다.\n",
    "input_size = 784         # MNIST 데이터 input (이미지 크기: 28*28)\n",
    "hidden1_size = 128       # 첫번째 히든레이어의 노드 개수 \n",
    "hidden2_size = 64        # 두번째 히든레이어의 노드 개수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-646c83931caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 인풋을 위한 플레이스홀더를 정의합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# True MNIST 숫자값\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, input_size])   # 인풋을 위한 플레이스홀더를 정의합니다.\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])           # True MNIST 숫자값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ae80da9abf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 다운로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# 이미지들을 float32 데이터 타입으로 변경합니다.\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "# 28*28 형태의 이미지를 784차원으로 flattening 합니다.\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784]) #-1 이 None과 같음.\n",
    "# [0, 255] 사이의 값을 [0, 1]사이의 값으로 Normalize합니다.\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "training_epochs = 50    # 반복횟수\n",
    "batch_size = 256        # 배치개수\n",
    "display_step = 1        # 손실함수 출력 주기\n",
    "examples_to_show = 10   # 보여줄 MNIST Reconstruction 이미지 개수\n",
    "input_size = 784        # 28*28\n",
    "hidden1_size = 256 \n",
    "hidden2_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_data = train_data.shuffle(60000).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 784), types: tf.float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "  # Autoencoder 모델을 위한 tf.Variable들을 정의합니다.\n",
    "  def __init__(self):\n",
    "    # 인코딩(Encoding) - 784 -> 256 -> 128\n",
    "    self.W1 = tf.Variable(tf.random.normal(shape=[input_size, hidden1_size]))\n",
    "    self.b1 = tf.Variable(tf.random.normal(shape=[hidden1_size]))\n",
    "    self.W2 = tf.Variable(tf.random.normal(shape=[hidden1_size, hidden2_size]))\n",
    "    self.b2 = tf.Variable(tf.random.normal(shape=[hidden2_size]))\n",
    "    # 디코딩(Decoding) 128 -> 256 -> 784\n",
    "    self.W3 = tf.Variable(tf.random.normal(shape=[hidden2_size, hidden1_size]))\n",
    "    self.b3 = tf.Variable(tf.random.normal(shape=[hidden1_size]))\n",
    "    self.W4 = tf.Variable(tf.random.normal(shape=[hidden1_size, input_size]))\n",
    "    self.b4 = tf.Variable(tf.random.normal(shape=[input_size]))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    H1_output = tf.nn.sigmoid(tf.matmul(x, self.W1) + self.b1)\n",
    "    H2_output = tf.nn.sigmoid(tf.matmul(H1_output, self.W2) + self.b2)\n",
    "    H3_output = tf.nn.sigmoid(tf.matmul(H2_output, self.W3) + self.b3)\n",
    "    reconstructed_x = tf.nn.sigmoid(tf.matmul(H3_output, self.W4) + self.b4)\n",
    "\n",
    "    return reconstructed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mse_loss(y_pred, y_true):\n",
    "  return tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE(Mean of Squared Error) 손실함수\n",
    "\n",
    "# 최적화를 위한 RMSProp 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.RMSprop(learning_rate)\n",
    "\n",
    "# 최적화를 위한 function을 정의합니다.\n",
    "@tf.function\n",
    "def train_step(model, x):\n",
    "  # 타겟데이터는 인풋데이터와 같습니다.\n",
    "  y_true = x\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred = model(x)\n",
    "    loss = mse_loss(y_pred, y_true)\n",
    "  gradients = tape.gradient(loss, vars(model).values())\n",
    "  optimizer.apply_gradients(zip(gradients, vars(model).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.AutoEncoder object at 0x7f6f2450def0>\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder 모델을 선언합니다.\n",
    "AutoEncoder_model = AutoEncoder()\n",
    "print(AutoEncoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, 손실 함수(Loss): 0.062491\n",
      "반복(Epoch): 2, 손실 함수(Loss): 0.051753\n",
      "반복(Epoch): 3, 손실 함수(Loss): 0.049540\n",
      "반복(Epoch): 4, 손실 함수(Loss): 0.040989\n",
      "반복(Epoch): 5, 손실 함수(Loss): 0.036644\n",
      "반복(Epoch): 6, 손실 함수(Loss): 0.037334\n",
      "반복(Epoch): 7, 손실 함수(Loss): 0.036369\n",
      "반복(Epoch): 8, 손실 함수(Loss): 0.036626\n",
      "반복(Epoch): 9, 손실 함수(Loss): 0.035895\n",
      "반복(Epoch): 10, 손실 함수(Loss): 0.032516\n",
      "반복(Epoch): 11, 손실 함수(Loss): 0.034403\n",
      "반복(Epoch): 12, 손실 함수(Loss): 0.031236\n",
      "반복(Epoch): 13, 손실 함수(Loss): 0.032125\n",
      "반복(Epoch): 14, 손실 함수(Loss): 0.031651\n",
      "반복(Epoch): 15, 손실 함수(Loss): 0.033587\n",
      "반복(Epoch): 16, 손실 함수(Loss): 0.029577\n",
      "반복(Epoch): 17, 손실 함수(Loss): 0.029367\n",
      "반복(Epoch): 18, 손실 함수(Loss): 0.032236\n",
      "반복(Epoch): 19, 손실 함수(Loss): 0.029614\n",
      "반복(Epoch): 20, 손실 함수(Loss): 0.030271\n",
      "반복(Epoch): 21, 손실 함수(Loss): 0.031797\n",
      "반복(Epoch): 22, 손실 함수(Loss): 0.031008\n",
      "반복(Epoch): 23, 손실 함수(Loss): 0.032260\n",
      "반복(Epoch): 24, 손실 함수(Loss): 0.030107\n",
      "반복(Epoch): 25, 손실 함수(Loss): 0.028411\n",
      "반복(Epoch): 26, 손실 함수(Loss): 0.028466\n",
      "반복(Epoch): 27, 손실 함수(Loss): 0.029251\n",
      "반복(Epoch): 28, 손실 함수(Loss): 0.026050\n",
      "반복(Epoch): 29, 손실 함수(Loss): 0.029075\n",
      "반복(Epoch): 30, 손실 함수(Loss): 0.026495\n",
      "반복(Epoch): 31, 손실 함수(Loss): 0.030466\n",
      "반복(Epoch): 32, 손실 함수(Loss): 0.030998\n",
      "반복(Epoch): 33, 손실 함수(Loss): 0.027773\n",
      "반복(Epoch): 34, 손실 함수(Loss): 0.029966\n",
      "반복(Epoch): 35, 손실 함수(Loss): 0.025442\n",
      "반복(Epoch): 36, 손실 함수(Loss): 0.028232\n",
      "반복(Epoch): 37, 손실 함수(Loss): 0.023852\n",
      "반복(Epoch): 38, 손실 함수(Loss): 0.025611\n",
      "반복(Epoch): 39, 손실 함수(Loss): 0.024930\n",
      "반복(Epoch): 40, 손실 함수(Loss): 0.025607\n",
      "반복(Epoch): 41, 손실 함수(Loss): 0.021513\n",
      "반복(Epoch): 42, 손실 함수(Loss): 0.023386\n",
      "반복(Epoch): 43, 손실 함수(Loss): 0.025750\n",
      "반복(Epoch): 44, 손실 함수(Loss): 0.025601\n",
      "반복(Epoch): 45, 손실 함수(Loss): 0.023678\n",
      "반복(Epoch): 46, 손실 함수(Loss): 0.024495\n",
      "반복(Epoch): 47, 손실 함수(Loss): 0.024856\n",
      "반복(Epoch): 48, 손실 함수(Loss): 0.028331\n",
      "반복(Epoch): 49, 손실 함수(Loss): 0.022253\n",
      "반복(Epoch): 50, 손실 함수(Loss): 0.025419\n"
     ]
    }
   ],
   "source": [
    "# 지정된 횟수만큼 최적화를 수행합니다.\n",
    "for epoch in range(training_epochs):\n",
    "  # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "  # Autoencoder는 Unsupervised Learning이므로 타겟 레이블(label) y가 필요하지 않습니다.\n",
    "  for batch_x in train_data:\n",
    "    # 옵티마이저를 실행해서 파라마터들을 업데이트합니다.\n",
    "    _, current_loss = train_step(AutoEncoder_model, batch_x), mse_loss(AutoEncoder_model(batch_x), batch_x)\n",
    "  # 지정된 epoch마다 학습결과를 출력합니다.\n",
    "  if epoch % display_step == 0:\n",
    "    print(\"반복(Epoch): %d, 손실 함수(Loss): %f\" % ((epoch+1), current_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 Reconstruction을 수행합니다.\n",
    "reconstructed_result = AutoEncoder_model(x_test[:examples_to_show])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, a = plt.subplots(2, 10, figsize=(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/givenone/morpheus/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstructed_result = AutoEncoder_model(x_test[:examples_to_show])\n",
    "# 원본 MNIST 데이터와 Reconstruction 결과를 비교합니다.\n",
    "f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(examples_to_show):\n",
    "  a[0][i].imshow(np.reshape(x_test[i], (28, 28)))\n",
    "  a[1][i].imshow(np.reshape(reconstructed_result[i], (28, 28)))\n",
    "#f.savefig('reconstructed_mnist_image.png')  # reconstruction 결과를 png로 저장합니다.\n",
    "f.show()\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# MNIST 데이터를 다운로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# 이미지들을 float32 데이터 타입으로 변경합니다.\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "# 28*28 형태의 이미지를 784차원으로 flattening 합니다.\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "# [0, 255] 사이의 값을 [0, 1]사이의 값으로 Normalize합니다.\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "# 학습에 필요한 설정값들을 정의합니다.\n",
    "learning_rate_RMSProp = 0.02\n",
    "learning_rate_GradientDescent = 0.5\n",
    "num_epochs = 100         # 반복횟수\n",
    "batch_size = 256\n",
    "display_step = 1         # 몇 Step마다 log를 출력할지 결정합니다.\n",
    "input_size = 784         # MNIST 데이터 input (이미지 크기: 28*28)\n",
    "hidden1_size = 128       # 첫번째 히든레이어의 노드 개수 \n",
    "hidden2_size = 64        # 두번째 히든레이어의 노드 개수 \n",
    "\n",
    "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(60000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_normal_intializer_with_stddev_1():\n",
    "  return tf.keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(AutoEncoder, self).__init__()\n",
    "    # 인코딩(Encoding) - 784 -> 128 -> 64\n",
    "    self.hidden_layer_1 = tf.keras.layers.Dense(hidden1_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    self.hidden_layer_2 = tf.keras.layers.Dense(hidden2_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    # 디코딩(Decoding) 64 -> 128 -> 784\n",
    "    self.hidden_layer_3 = tf.keras.layers.Dense(hidden1_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    self.output_layer = tf.keras.layers.Dense(input_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(AutoEncoder, self).__init__()\n",
    "    # 인코딩(Encoding) - 784 -> 128 -> 64\n",
    "    self.hidden_layer_1 = tf.keras.layers.Dense(hidden1_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    self.hidden_layer_2 = tf.keras.layers.Dense(hidden2_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    # 디코딩(Decoding) 64 -> 128 -> 784\n",
    "    self.hidden_layer_3 = tf.keras.layers.Dense(hidden1_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "    self.output_layer = tf.keras.layers.Dense(input_size,\n",
    "                                                activation='sigmoid',\n",
    "                                                kernel_initializer=random_normal_intializer_with_stddev_1(),\n",
    "                                                bias_initializer=random_normal_intializer_with_stddev_1())\n",
    "\n",
    "  def call(self, x):\n",
    "    H1_output = self.hidden_layer_1(x)\n",
    "    H2_output = self.hidden_layer_2(H1_output)\n",
    "    H3_output = self.hidden_layer_3(H2_output)\n",
    "    X_reconstructed = self.output_layer(H3_output)\n",
    "\n",
    "    return X_reconstructed, H2_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.Model을 이용해서 Softmax 분류기를 정의합니다.\n",
    "class SoftmaxClassifier(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(SoftmaxClassifier, self).__init__()\n",
    "    # 원본 MNIST 이미지(784) 대신 오토인코더의 압축된 특징(64)을 입력값으로 받습니다.\n",
    "    self.softmax_layer = tf.keras.layers.Dense(10,\n",
    "                                               activation='softmax',\n",
    "                                               kernel_initializer='zeros',\n",
    "                                               bias_initializer='zeros')\n",
    "\n",
    "  def call(self, x):\n",
    "    y_pred = self.softmax_layer(x)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def pretraining_mse_loss(y_pred, y_true):\n",
    "  return tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE(Mean of Squared Error) 손실함수\n",
    "\n",
    "@tf.function\n",
    "def finetuning_cross_entropy_loss(y_pred_softmax, y):\n",
    "  return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_pred_softmax), axis=[1]))     # cross-entropy loss 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre- Training\n",
    "pretraining_optimizer = tf.optimizers.RMSprop(learning_rate_RMSProp, epsilon=1e-10)\n",
    "@tf.function\n",
    "def pretraining_train_step(autoencoder_model, x):\n",
    "  # 타겟데이터는 인풋데이터와 같습니다.\n",
    "  y_true = x\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred, _ = autoencoder_model(x)\n",
    "    pretraining_loss = pretraining_mse_loss(y_pred, y_true)\n",
    "  gradients = tape.gradient(pretraining_loss, autoencoder_model.trainable_variables)\n",
    "  pretraining_optimizer.apply_gradients(zip(gradients, autoencoder_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_optimizer = tf.optimizers.SGD(learning_rate_GradientDescent)\n",
    "@tf.function\n",
    "def finetuning_train_step(autoencoder_model, softmax_classifier_model, x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_pred, extracted_features = autoencoder_model(x)\n",
    "    y_pred_softmax = softmax_classifier_model(extracted_features)\n",
    "    finetuning_loss = finetuning_cross_entropy_loss(y_pred_softmax, y)\n",
    "  autoencoder_encoding_variables = autoencoder_model.hidden_layer_1.trainable_variables + autoencoder_model.hidden_layer_2.trainable_variables\n",
    "  gradients = tape.gradient(finetuning_loss, autoencoder_encoding_variables + softmax_classifier_model.trainable_variables)\n",
    "  finetuning_optimizer.apply_gradients(zip(gradients, autoencoder_encoding_variables + softmax_classifier_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_accuracy(y_pred_softmax, y):\n",
    "  correct_prediction = tf.equal(tf.argmax(y_pred_softmax,1), tf.argmax(y,1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder 모델을 선언합니다.\n",
    "AutoEncoder_model = AutoEncoder()\n",
    "# Softmax 분류기 모델을 선언합니다. (입력으로 Autoencoder의 압축된 특징을 넣습니다.)\n",
    "SoftmaxClassifier_model = SoftmaxClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, Pre-Training 손실 함수(pretraining_loss): 0.054252\n",
      "반복(Epoch): 2, Pre-Training 손실 함수(pretraining_loss): 0.039407\n",
      "반복(Epoch): 3, Pre-Training 손실 함수(pretraining_loss): 0.034838\n",
      "반복(Epoch): 4, Pre-Training 손실 함수(pretraining_loss): 0.031940\n",
      "반복(Epoch): 5, Pre-Training 손실 함수(pretraining_loss): 0.031021\n",
      "반복(Epoch): 6, Pre-Training 손실 함수(pretraining_loss): 0.036528\n",
      "반복(Epoch): 7, Pre-Training 손실 함수(pretraining_loss): 0.028920\n",
      "반복(Epoch): 8, Pre-Training 손실 함수(pretraining_loss): 0.031571\n",
      "반복(Epoch): 9, Pre-Training 손실 함수(pretraining_loss): 0.027775\n",
      "반복(Epoch): 10, Pre-Training 손실 함수(pretraining_loss): 0.023759\n",
      "반복(Epoch): 11, Pre-Training 손실 함수(pretraining_loss): 0.028270\n",
      "반복(Epoch): 12, Pre-Training 손실 함수(pretraining_loss): 0.026073\n",
      "반복(Epoch): 13, Pre-Training 손실 함수(pretraining_loss): 0.026678\n",
      "반복(Epoch): 14, Pre-Training 손실 함수(pretraining_loss): 0.023894\n",
      "반복(Epoch): 15, Pre-Training 손실 함수(pretraining_loss): 0.026423\n",
      "반복(Epoch): 16, Pre-Training 손실 함수(pretraining_loss): 0.024048\n",
      "반복(Epoch): 17, Pre-Training 손실 함수(pretraining_loss): 0.027211\n",
      "반복(Epoch): 18, Pre-Training 손실 함수(pretraining_loss): 0.021543\n",
      "반복(Epoch): 19, Pre-Training 손실 함수(pretraining_loss): 0.026104\n",
      "반복(Epoch): 20, Pre-Training 손실 함수(pretraining_loss): 0.022003\n",
      "반복(Epoch): 21, Pre-Training 손실 함수(pretraining_loss): 0.023744\n",
      "반복(Epoch): 22, Pre-Training 손실 함수(pretraining_loss): 0.025835\n",
      "반복(Epoch): 23, Pre-Training 손실 함수(pretraining_loss): 0.027883\n",
      "반복(Epoch): 24, Pre-Training 손실 함수(pretraining_loss): 0.021129\n",
      "반복(Epoch): 25, Pre-Training 손실 함수(pretraining_loss): 0.020794\n",
      "반복(Epoch): 26, Pre-Training 손실 함수(pretraining_loss): 0.021960\n",
      "반복(Epoch): 27, Pre-Training 손실 함수(pretraining_loss): 0.024178\n",
      "반복(Epoch): 28, Pre-Training 손실 함수(pretraining_loss): 0.024497\n",
      "반복(Epoch): 29, Pre-Training 손실 함수(pretraining_loss): 0.019561\n",
      "반복(Epoch): 30, Pre-Training 손실 함수(pretraining_loss): 0.023016\n",
      "반복(Epoch): 31, Pre-Training 손실 함수(pretraining_loss): 0.020068\n",
      "반복(Epoch): 32, Pre-Training 손실 함수(pretraining_loss): 0.021795\n",
      "반복(Epoch): 33, Pre-Training 손실 함수(pretraining_loss): 0.021325\n",
      "반복(Epoch): 34, Pre-Training 손실 함수(pretraining_loss): 0.019957\n",
      "반복(Epoch): 35, Pre-Training 손실 함수(pretraining_loss): 0.022432\n",
      "반복(Epoch): 36, Pre-Training 손실 함수(pretraining_loss): 0.019100\n",
      "반복(Epoch): 37, Pre-Training 손실 함수(pretraining_loss): 0.020220\n",
      "반복(Epoch): 38, Pre-Training 손실 함수(pretraining_loss): 0.020842\n",
      "반복(Epoch): 39, Pre-Training 손실 함수(pretraining_loss): 0.017244\n",
      "반복(Epoch): 40, Pre-Training 손실 함수(pretraining_loss): 0.017303\n",
      "반복(Epoch): 41, Pre-Training 손실 함수(pretraining_loss): 0.017680\n",
      "반복(Epoch): 42, Pre-Training 손실 함수(pretraining_loss): 0.019814\n",
      "반복(Epoch): 43, Pre-Training 손실 함수(pretraining_loss): 0.019542\n",
      "반복(Epoch): 44, Pre-Training 손실 함수(pretraining_loss): 0.018089\n",
      "반복(Epoch): 45, Pre-Training 손실 함수(pretraining_loss): 0.019254\n",
      "반복(Epoch): 46, Pre-Training 손실 함수(pretraining_loss): 0.018788\n",
      "반복(Epoch): 47, Pre-Training 손실 함수(pretraining_loss): 0.018625\n",
      "반복(Epoch): 48, Pre-Training 손실 함수(pretraining_loss): 0.016145\n",
      "반복(Epoch): 49, Pre-Training 손실 함수(pretraining_loss): 0.017207\n",
      "반복(Epoch): 50, Pre-Training 손실 함수(pretraining_loss): 0.018383\n",
      "반복(Epoch): 51, Pre-Training 손실 함수(pretraining_loss): 0.015651\n",
      "반복(Epoch): 52, Pre-Training 손실 함수(pretraining_loss): 0.015567\n",
      "반복(Epoch): 53, Pre-Training 손실 함수(pretraining_loss): 0.017286\n",
      "반복(Epoch): 54, Pre-Training 손실 함수(pretraining_loss): 0.013672\n",
      "반복(Epoch): 55, Pre-Training 손실 함수(pretraining_loss): 0.015440\n",
      "반복(Epoch): 56, Pre-Training 손실 함수(pretraining_loss): 0.016335\n",
      "반복(Epoch): 57, Pre-Training 손실 함수(pretraining_loss): 0.015457\n",
      "반복(Epoch): 58, Pre-Training 손실 함수(pretraining_loss): 0.015026\n",
      "반복(Epoch): 59, Pre-Training 손실 함수(pretraining_loss): 0.016575\n",
      "반복(Epoch): 60, Pre-Training 손실 함수(pretraining_loss): 0.014895\n",
      "반복(Epoch): 61, Pre-Training 손실 함수(pretraining_loss): 0.014406\n",
      "반복(Epoch): 62, Pre-Training 손실 함수(pretraining_loss): 0.013911\n",
      "반복(Epoch): 63, Pre-Training 손실 함수(pretraining_loss): 0.015846\n",
      "반복(Epoch): 64, Pre-Training 손실 함수(pretraining_loss): 0.014841\n",
      "반복(Epoch): 65, Pre-Training 손실 함수(pretraining_loss): 0.014886\n",
      "반복(Epoch): 66, Pre-Training 손실 함수(pretraining_loss): 0.013610\n",
      "반복(Epoch): 67, Pre-Training 손실 함수(pretraining_loss): 0.013009\n",
      "반복(Epoch): 68, Pre-Training 손실 함수(pretraining_loss): 0.013688\n",
      "반복(Epoch): 69, Pre-Training 손실 함수(pretraining_loss): 0.014602\n",
      "반복(Epoch): 70, Pre-Training 손실 함수(pretraining_loss): 0.013138\n",
      "반복(Epoch): 71, Pre-Training 손실 함수(pretraining_loss): 0.013024\n",
      "반복(Epoch): 72, Pre-Training 손실 함수(pretraining_loss): 0.013606\n",
      "반복(Epoch): 73, Pre-Training 손실 함수(pretraining_loss): 0.013173\n",
      "반복(Epoch): 74, Pre-Training 손실 함수(pretraining_loss): 0.012263\n",
      "반복(Epoch): 75, Pre-Training 손실 함수(pretraining_loss): 0.012657\n",
      "반복(Epoch): 76, Pre-Training 손실 함수(pretraining_loss): 0.012271\n",
      "반복(Epoch): 77, Pre-Training 손실 함수(pretraining_loss): 0.012985\n",
      "반복(Epoch): 78, Pre-Training 손실 함수(pretraining_loss): 0.012097\n",
      "반복(Epoch): 79, Pre-Training 손실 함수(pretraining_loss): 0.012184\n",
      "반복(Epoch): 80, Pre-Training 손실 함수(pretraining_loss): 0.015356\n",
      "반복(Epoch): 81, Pre-Training 손실 함수(pretraining_loss): 0.013469\n",
      "반복(Epoch): 82, Pre-Training 손실 함수(pretraining_loss): 0.013373\n",
      "반복(Epoch): 83, Pre-Training 손실 함수(pretraining_loss): 0.012569\n",
      "반복(Epoch): 84, Pre-Training 손실 함수(pretraining_loss): 0.013246\n",
      "반복(Epoch): 85, Pre-Training 손실 함수(pretraining_loss): 0.012584\n",
      "반복(Epoch): 86, Pre-Training 손실 함수(pretraining_loss): 0.011007\n",
      "반복(Epoch): 87, Pre-Training 손실 함수(pretraining_loss): 0.014183\n",
      "반복(Epoch): 88, Pre-Training 손실 함수(pretraining_loss): 0.011873\n",
      "반복(Epoch): 89, Pre-Training 손실 함수(pretraining_loss): 0.013770\n",
      "반복(Epoch): 90, Pre-Training 손실 함수(pretraining_loss): 0.012408\n",
      "반복(Epoch): 91, Pre-Training 손실 함수(pretraining_loss): 0.012578\n",
      "반복(Epoch): 92, Pre-Training 손실 함수(pretraining_loss): 0.013792\n",
      "반복(Epoch): 93, Pre-Training 손실 함수(pretraining_loss): 0.013131\n",
      "반복(Epoch): 94, Pre-Training 손실 함수(pretraining_loss): 0.012357\n",
      "반복(Epoch): 95, Pre-Training 손실 함수(pretraining_loss): 0.011843\n",
      "반복(Epoch): 96, Pre-Training 손실 함수(pretraining_loss): 0.011893\n",
      "반복(Epoch): 97, Pre-Training 손실 함수(pretraining_loss): 0.010873\n",
      "반복(Epoch): 98, Pre-Training 손실 함수(pretraining_loss): 0.012733\n",
      "반복(Epoch): 99, Pre-Training 손실 함수(pretraining_loss): 0.011565\n",
      "반복(Epoch): 100, Pre-Training 손실 함수(pretraining_loss): 0.010559\n",
      "Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "  for batch_x, _ in train_data:\n",
    "    _, pretraining_loss_print = pretraining_train_step(AutoEncoder_model, batch_x), pretraining_mse_loss(AutoEncoder_model(batch_x)[0], batch_x)\n",
    "  # 지정된 epoch마다 학습결과를 출력합니다.\n",
    "  if epoch % display_step == 0:\n",
    "    print(\"반복(Epoch): %d, Pre-Training 손실 함수(pretraining_loss): %f\" % ((epoch + 1), pretraining_loss_print))\n",
    "print(\"Step 1 : MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AutoEncoder_model.hidden_layer_2.trainable_variables + AutoEncoder_model.hidden_layer_1.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, Fine-tuning 손실 함수(finetuning_loss): 0.512844\n",
      "반복(Epoch): 2, Fine-tuning 손실 함수(finetuning_loss): 0.321322\n",
      "반복(Epoch): 3, Fine-tuning 손실 함수(finetuning_loss): 0.482537\n",
      "반복(Epoch): 4, Fine-tuning 손실 함수(finetuning_loss): 0.280574\n",
      "반복(Epoch): 5, Fine-tuning 손실 함수(finetuning_loss): 0.145813\n",
      "반복(Epoch): 6, Fine-tuning 손실 함수(finetuning_loss): 0.157173\n",
      "반복(Epoch): 7, Fine-tuning 손실 함수(finetuning_loss): 0.134000\n",
      "반복(Epoch): 8, Fine-tuning 손실 함수(finetuning_loss): 0.255357\n",
      "반복(Epoch): 9, Fine-tuning 손실 함수(finetuning_loss): 0.185198\n",
      "반복(Epoch): 10, Fine-tuning 손실 함수(finetuning_loss): 0.091456\n",
      "반복(Epoch): 11, Fine-tuning 손실 함수(finetuning_loss): 0.076445\n",
      "반복(Epoch): 12, Fine-tuning 손실 함수(finetuning_loss): 0.171736\n",
      "반복(Epoch): 13, Fine-tuning 손실 함수(finetuning_loss): 0.187210\n",
      "반복(Epoch): 14, Fine-tuning 손실 함수(finetuning_loss): 0.162905\n",
      "반복(Epoch): 15, Fine-tuning 손실 함수(finetuning_loss): 0.103447\n",
      "반복(Epoch): 16, Fine-tuning 손실 함수(finetuning_loss): 0.122351\n",
      "반복(Epoch): 17, Fine-tuning 손실 함수(finetuning_loss): 0.105098\n",
      "반복(Epoch): 18, Fine-tuning 손실 함수(finetuning_loss): 0.127990\n",
      "반복(Epoch): 19, Fine-tuning 손실 함수(finetuning_loss): 0.081753\n",
      "반복(Epoch): 20, Fine-tuning 손실 함수(finetuning_loss): 0.107519\n",
      "반복(Epoch): 21, Fine-tuning 손실 함수(finetuning_loss): 0.098184\n",
      "반복(Epoch): 22, Fine-tuning 손실 함수(finetuning_loss): 0.072302\n",
      "반복(Epoch): 23, Fine-tuning 손실 함수(finetuning_loss): 0.092359\n",
      "반복(Epoch): 24, Fine-tuning 손실 함수(finetuning_loss): 0.140127\n",
      "반복(Epoch): 25, Fine-tuning 손실 함수(finetuning_loss): 0.046942\n",
      "반복(Epoch): 26, Fine-tuning 손실 함수(finetuning_loss): 0.097822\n",
      "반복(Epoch): 27, Fine-tuning 손실 함수(finetuning_loss): 0.050013\n",
      "반복(Epoch): 28, Fine-tuning 손실 함수(finetuning_loss): 0.127953\n",
      "반복(Epoch): 29, Fine-tuning 손실 함수(finetuning_loss): 0.082898\n",
      "반복(Epoch): 30, Fine-tuning 손실 함수(finetuning_loss): 0.125803\n",
      "반복(Epoch): 31, Fine-tuning 손실 함수(finetuning_loss): 0.092458\n",
      "반복(Epoch): 32, Fine-tuning 손실 함수(finetuning_loss): 0.101884\n",
      "반복(Epoch): 33, Fine-tuning 손실 함수(finetuning_loss): 0.057674\n",
      "반복(Epoch): 34, Fine-tuning 손실 함수(finetuning_loss): 0.061733\n",
      "반복(Epoch): 35, Fine-tuning 손실 함수(finetuning_loss): 0.091619\n",
      "반복(Epoch): 36, Fine-tuning 손실 함수(finetuning_loss): 0.122399\n",
      "반복(Epoch): 37, Fine-tuning 손실 함수(finetuning_loss): 0.076362\n",
      "반복(Epoch): 38, Fine-tuning 손실 함수(finetuning_loss): 0.064652\n",
      "반복(Epoch): 39, Fine-tuning 손실 함수(finetuning_loss): 0.154766\n",
      "반복(Epoch): 40, Fine-tuning 손실 함수(finetuning_loss): 0.043375\n",
      "반복(Epoch): 41, Fine-tuning 손실 함수(finetuning_loss): 0.058097\n",
      "반복(Epoch): 42, Fine-tuning 손실 함수(finetuning_loss): 0.040782\n",
      "반복(Epoch): 43, Fine-tuning 손실 함수(finetuning_loss): 0.077035\n",
      "반복(Epoch): 44, Fine-tuning 손실 함수(finetuning_loss): 0.087566\n",
      "반복(Epoch): 45, Fine-tuning 손실 함수(finetuning_loss): 0.087569\n",
      "반복(Epoch): 46, Fine-tuning 손실 함수(finetuning_loss): 0.037135\n",
      "반복(Epoch): 47, Fine-tuning 손실 함수(finetuning_loss): 0.059242\n",
      "반복(Epoch): 48, Fine-tuning 손실 함수(finetuning_loss): 0.017095\n",
      "반복(Epoch): 49, Fine-tuning 손실 함수(finetuning_loss): 0.074815\n",
      "반복(Epoch): 50, Fine-tuning 손실 함수(finetuning_loss): 0.053984\n",
      "반복(Epoch): 51, Fine-tuning 손실 함수(finetuning_loss): 0.038848\n",
      "반복(Epoch): 52, Fine-tuning 손실 함수(finetuning_loss): 0.052849\n",
      "반복(Epoch): 53, Fine-tuning 손실 함수(finetuning_loss): 0.116273\n",
      "반복(Epoch): 54, Fine-tuning 손실 함수(finetuning_loss): 0.033210\n",
      "반복(Epoch): 55, Fine-tuning 손실 함수(finetuning_loss): 0.085841\n",
      "반복(Epoch): 56, Fine-tuning 손실 함수(finetuning_loss): 0.033328\n",
      "반복(Epoch): 57, Fine-tuning 손실 함수(finetuning_loss): 0.055445\n",
      "반복(Epoch): 58, Fine-tuning 손실 함수(finetuning_loss): 0.060843\n",
      "반복(Epoch): 59, Fine-tuning 손실 함수(finetuning_loss): 0.039347\n",
      "반복(Epoch): 60, Fine-tuning 손실 함수(finetuning_loss): 0.045614\n",
      "반복(Epoch): 61, Fine-tuning 손실 함수(finetuning_loss): 0.049509\n",
      "반복(Epoch): 62, Fine-tuning 손실 함수(finetuning_loss): 0.029300\n",
      "반복(Epoch): 63, Fine-tuning 손실 함수(finetuning_loss): 0.029019\n",
      "반복(Epoch): 64, Fine-tuning 손실 함수(finetuning_loss): 0.087548\n",
      "반복(Epoch): 65, Fine-tuning 손실 함수(finetuning_loss): 0.071234\n",
      "반복(Epoch): 66, Fine-tuning 손실 함수(finetuning_loss): 0.065140\n",
      "반복(Epoch): 67, Fine-tuning 손실 함수(finetuning_loss): 0.033711\n",
      "반복(Epoch): 68, Fine-tuning 손실 함수(finetuning_loss): 0.043097\n",
      "반복(Epoch): 69, Fine-tuning 손실 함수(finetuning_loss): 0.070941\n",
      "반복(Epoch): 70, Fine-tuning 손실 함수(finetuning_loss): 0.060857\n",
      "반복(Epoch): 71, Fine-tuning 손실 함수(finetuning_loss): 0.099415\n",
      "반복(Epoch): 72, Fine-tuning 손실 함수(finetuning_loss): 0.100850\n",
      "반복(Epoch): 73, Fine-tuning 손실 함수(finetuning_loss): 0.051344\n",
      "반복(Epoch): 74, Fine-tuning 손실 함수(finetuning_loss): 0.046394\n",
      "반복(Epoch): 75, Fine-tuning 손실 함수(finetuning_loss): 0.027631\n",
      "반복(Epoch): 76, Fine-tuning 손실 함수(finetuning_loss): 0.105387\n",
      "반복(Epoch): 77, Fine-tuning 손실 함수(finetuning_loss): 0.094474\n",
      "반복(Epoch): 78, Fine-tuning 손실 함수(finetuning_loss): 0.008907\n",
      "반복(Epoch): 79, Fine-tuning 손실 함수(finetuning_loss): 0.067557\n",
      "반복(Epoch): 80, Fine-tuning 손실 함수(finetuning_loss): 0.058242\n",
      "반복(Epoch): 81, Fine-tuning 손실 함수(finetuning_loss): 0.033032\n",
      "반복(Epoch): 82, Fine-tuning 손실 함수(finetuning_loss): 0.030971\n",
      "반복(Epoch): 83, Fine-tuning 손실 함수(finetuning_loss): 0.036832\n",
      "반복(Epoch): 84, Fine-tuning 손실 함수(finetuning_loss): 0.034318\n",
      "반복(Epoch): 85, Fine-tuning 손실 함수(finetuning_loss): 0.057076\n",
      "반복(Epoch): 86, Fine-tuning 손실 함수(finetuning_loss): 0.023450\n",
      "반복(Epoch): 87, Fine-tuning 손실 함수(finetuning_loss): 0.067077\n",
      "반복(Epoch): 88, Fine-tuning 손실 함수(finetuning_loss): 0.053592\n",
      "반복(Epoch): 89, Fine-tuning 손실 함수(finetuning_loss): 0.047123\n",
      "반복(Epoch): 90, Fine-tuning 손실 함수(finetuning_loss): 0.032520\n",
      "반복(Epoch): 91, Fine-tuning 손실 함수(finetuning_loss): 0.032293\n",
      "반복(Epoch): 92, Fine-tuning 손실 함수(finetuning_loss): 0.071517\n",
      "반복(Epoch): 93, Fine-tuning 손실 함수(finetuning_loss): 0.052814\n",
      "반복(Epoch): 94, Fine-tuning 손실 함수(finetuning_loss): 0.020473\n",
      "반복(Epoch): 95, Fine-tuning 손실 함수(finetuning_loss): 0.046655\n",
      "반복(Epoch): 96, Fine-tuning 손실 함수(finetuning_loss): 0.016354\n",
      "반복(Epoch): 97, Fine-tuning 손실 함수(finetuning_loss): 0.017399\n",
      "반복(Epoch): 98, Fine-tuning 손실 함수(finetuning_loss): 0.024585\n",
      "반복(Epoch): 99, Fine-tuning 손실 함수(finetuning_loss): 0.024812\n",
      "반복(Epoch): 100, Fine-tuning 손실 함수(finetuning_loss): 0.057670\n",
      "반복(Epoch): 101, Fine-tuning 손실 함수(finetuning_loss): 0.043159\n",
      "반복(Epoch): 102, Fine-tuning 손실 함수(finetuning_loss): 0.044742\n",
      "반복(Epoch): 103, Fine-tuning 손실 함수(finetuning_loss): 0.038084\n",
      "반복(Epoch): 104, Fine-tuning 손실 함수(finetuning_loss): 0.037086\n",
      "반복(Epoch): 105, Fine-tuning 손실 함수(finetuning_loss): 0.057518\n",
      "반복(Epoch): 106, Fine-tuning 손실 함수(finetuning_loss): 0.015445\n",
      "반복(Epoch): 107, Fine-tuning 손실 함수(finetuning_loss): 0.074668\n",
      "반복(Epoch): 108, Fine-tuning 손실 함수(finetuning_loss): 0.043907\n",
      "반복(Epoch): 109, Fine-tuning 손실 함수(finetuning_loss): 0.085168\n",
      "반복(Epoch): 110, Fine-tuning 손실 함수(finetuning_loss): 0.037907\n",
      "반복(Epoch): 111, Fine-tuning 손실 함수(finetuning_loss): 0.011808\n",
      "반복(Epoch): 112, Fine-tuning 손실 함수(finetuning_loss): 0.038106\n",
      "반복(Epoch): 113, Fine-tuning 손실 함수(finetuning_loss): 0.024673\n",
      "반복(Epoch): 114, Fine-tuning 손실 함수(finetuning_loss): 0.017070\n",
      "반복(Epoch): 115, Fine-tuning 손실 함수(finetuning_loss): 0.026015\n",
      "반복(Epoch): 116, Fine-tuning 손실 함수(finetuning_loss): 0.030096\n",
      "반복(Epoch): 117, Fine-tuning 손실 함수(finetuning_loss): 0.033861\n",
      "반복(Epoch): 118, Fine-tuning 손실 함수(finetuning_loss): 0.025378\n",
      "반복(Epoch): 119, Fine-tuning 손실 함수(finetuning_loss): 0.009911\n",
      "반복(Epoch): 120, Fine-tuning 손실 함수(finetuning_loss): 0.026082\n",
      "반복(Epoch): 121, Fine-tuning 손실 함수(finetuning_loss): 0.028807\n",
      "반복(Epoch): 122, Fine-tuning 손실 함수(finetuning_loss): 0.019682\n",
      "반복(Epoch): 123, Fine-tuning 손실 함수(finetuning_loss): 0.055168\n",
      "반복(Epoch): 124, Fine-tuning 손실 함수(finetuning_loss): 0.035088\n",
      "반복(Epoch): 125, Fine-tuning 손실 함수(finetuning_loss): 0.010722\n",
      "반복(Epoch): 126, Fine-tuning 손실 함수(finetuning_loss): 0.018631\n",
      "반복(Epoch): 127, Fine-tuning 손실 함수(finetuning_loss): 0.011244\n",
      "반복(Epoch): 128, Fine-tuning 손실 함수(finetuning_loss): 0.026435\n",
      "반복(Epoch): 129, Fine-tuning 손실 함수(finetuning_loss): 0.037734\n",
      "반복(Epoch): 130, Fine-tuning 손실 함수(finetuning_loss): 0.040014\n",
      "반복(Epoch): 131, Fine-tuning 손실 함수(finetuning_loss): 0.019382\n",
      "반복(Epoch): 132, Fine-tuning 손실 함수(finetuning_loss): 0.034780\n",
      "반복(Epoch): 133, Fine-tuning 손실 함수(finetuning_loss): 0.015519\n",
      "반복(Epoch): 134, Fine-tuning 손실 함수(finetuning_loss): 0.033738\n",
      "반복(Epoch): 135, Fine-tuning 손실 함수(finetuning_loss): 0.047057\n",
      "반복(Epoch): 136, Fine-tuning 손실 함수(finetuning_loss): 0.019227\n",
      "반복(Epoch): 137, Fine-tuning 손실 함수(finetuning_loss): 0.028724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 138, Fine-tuning 손실 함수(finetuning_loss): 0.012012\n",
      "반복(Epoch): 139, Fine-tuning 손실 함수(finetuning_loss): 0.007042\n",
      "반복(Epoch): 140, Fine-tuning 손실 함수(finetuning_loss): 0.023430\n",
      "반복(Epoch): 141, Fine-tuning 손실 함수(finetuning_loss): 0.022693\n",
      "반복(Epoch): 142, Fine-tuning 손실 함수(finetuning_loss): 0.010108\n",
      "반복(Epoch): 143, Fine-tuning 손실 함수(finetuning_loss): 0.011053\n",
      "반복(Epoch): 144, Fine-tuning 손실 함수(finetuning_loss): 0.064638\n",
      "반복(Epoch): 145, Fine-tuning 손실 함수(finetuning_loss): 0.024859\n",
      "반복(Epoch): 146, Fine-tuning 손실 함수(finetuning_loss): 0.016001\n",
      "반복(Epoch): 147, Fine-tuning 손실 함수(finetuning_loss): 0.013062\n",
      "반복(Epoch): 148, Fine-tuning 손실 함수(finetuning_loss): 0.009952\n",
      "반복(Epoch): 149, Fine-tuning 손실 함수(finetuning_loss): 0.013058\n",
      "반복(Epoch): 150, Fine-tuning 손실 함수(finetuning_loss): 0.012180\n",
      "반복(Epoch): 151, Fine-tuning 손실 함수(finetuning_loss): 0.031376\n",
      "반복(Epoch): 152, Fine-tuning 손실 함수(finetuning_loss): 0.016952\n",
      "반복(Epoch): 153, Fine-tuning 손실 함수(finetuning_loss): 0.013530\n",
      "반복(Epoch): 154, Fine-tuning 손실 함수(finetuning_loss): 0.012372\n",
      "반복(Epoch): 155, Fine-tuning 손실 함수(finetuning_loss): 0.014956\n",
      "반복(Epoch): 156, Fine-tuning 손실 함수(finetuning_loss): 0.017432\n",
      "반복(Epoch): 157, Fine-tuning 손실 함수(finetuning_loss): 0.016539\n",
      "반복(Epoch): 158, Fine-tuning 손실 함수(finetuning_loss): 0.045707\n",
      "반복(Epoch): 159, Fine-tuning 손실 함수(finetuning_loss): 0.011343\n",
      "반복(Epoch): 160, Fine-tuning 손실 함수(finetuning_loss): 0.046512\n",
      "반복(Epoch): 161, Fine-tuning 손실 함수(finetuning_loss): 0.022042\n",
      "반복(Epoch): 162, Fine-tuning 손실 함수(finetuning_loss): 0.022153\n",
      "반복(Epoch): 163, Fine-tuning 손실 함수(finetuning_loss): 0.011581\n",
      "반복(Epoch): 164, Fine-tuning 손실 함수(finetuning_loss): 0.014024\n",
      "반복(Epoch): 165, Fine-tuning 손실 함수(finetuning_loss): 0.013323\n",
      "반복(Epoch): 166, Fine-tuning 손실 함수(finetuning_loss): 0.040941\n",
      "반복(Epoch): 167, Fine-tuning 손실 함수(finetuning_loss): 0.025298\n",
      "반복(Epoch): 168, Fine-tuning 손실 함수(finetuning_loss): 0.012362\n",
      "반복(Epoch): 169, Fine-tuning 손실 함수(finetuning_loss): 0.021162\n",
      "반복(Epoch): 170, Fine-tuning 손실 함수(finetuning_loss): 0.024101\n",
      "반복(Epoch): 171, Fine-tuning 손실 함수(finetuning_loss): 0.019376\n",
      "반복(Epoch): 172, Fine-tuning 손실 함수(finetuning_loss): 0.008361\n",
      "반복(Epoch): 173, Fine-tuning 손실 함수(finetuning_loss): 0.008114\n",
      "반복(Epoch): 174, Fine-tuning 손실 함수(finetuning_loss): 0.013671\n",
      "반복(Epoch): 175, Fine-tuning 손실 함수(finetuning_loss): 0.014986\n",
      "반복(Epoch): 176, Fine-tuning 손실 함수(finetuning_loss): 0.008546\n",
      "반복(Epoch): 177, Fine-tuning 손실 함수(finetuning_loss): 0.004632\n",
      "반복(Epoch): 178, Fine-tuning 손실 함수(finetuning_loss): 0.015382\n",
      "반복(Epoch): 179, Fine-tuning 손실 함수(finetuning_loss): 0.012445\n",
      "반복(Epoch): 180, Fine-tuning 손실 함수(finetuning_loss): 0.018919\n",
      "반복(Epoch): 181, Fine-tuning 손실 함수(finetuning_loss): 0.013970\n",
      "반복(Epoch): 182, Fine-tuning 손실 함수(finetuning_loss): 0.009308\n",
      "반복(Epoch): 183, Fine-tuning 손실 함수(finetuning_loss): 0.009566\n",
      "반복(Epoch): 184, Fine-tuning 손실 함수(finetuning_loss): 0.012786\n",
      "반복(Epoch): 185, Fine-tuning 손실 함수(finetuning_loss): 0.013059\n",
      "반복(Epoch): 186, Fine-tuning 손실 함수(finetuning_loss): 0.009522\n",
      "반복(Epoch): 187, Fine-tuning 손실 함수(finetuning_loss): 0.008923\n",
      "반복(Epoch): 188, Fine-tuning 손실 함수(finetuning_loss): 0.014387\n",
      "반복(Epoch): 189, Fine-tuning 손실 함수(finetuning_loss): 0.021656\n",
      "반복(Epoch): 190, Fine-tuning 손실 함수(finetuning_loss): 0.012647\n",
      "반복(Epoch): 191, Fine-tuning 손실 함수(finetuning_loss): 0.019588\n",
      "반복(Epoch): 192, Fine-tuning 손실 함수(finetuning_loss): 0.017294\n",
      "반복(Epoch): 193, Fine-tuning 손실 함수(finetuning_loss): 0.013726\n",
      "반복(Epoch): 194, Fine-tuning 손실 함수(finetuning_loss): 0.016984\n",
      "반복(Epoch): 195, Fine-tuning 손실 함수(finetuning_loss): 0.010122\n",
      "반복(Epoch): 196, Fine-tuning 손실 함수(finetuning_loss): 0.005193\n",
      "반복(Epoch): 197, Fine-tuning 손실 함수(finetuning_loss): 0.011598\n",
      "반복(Epoch): 198, Fine-tuning 손실 함수(finetuning_loss): 0.017887\n",
      "반복(Epoch): 199, Fine-tuning 손실 함수(finetuning_loss): 0.016555\n",
      "반복(Epoch): 200, Fine-tuning 손실 함수(finetuning_loss): 0.008542\n",
      "Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\n",
      "정확도(오토인코더+Softmax 분류기): 0.963100\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs + 100):\n",
    "  # 모든 배치들에 대해서 최적화를 수행합니다.\n",
    "  for batch_x, batch_y in train_data:\n",
    "    batch_y = tf.one_hot(batch_y, depth=10)\n",
    "    _, finetuning_loss_print = finetuning_train_step(AutoEncoder_model, SoftmaxClassifier_model, batch_x, batch_y), finetuning_cross_entropy_loss(SoftmaxClassifier_model(AutoEncoder_model(batch_x)[1]), batch_y)\n",
    "  # 지정된 epoch마다 학습결과를 출력합니다.\n",
    "  if epoch % display_step == 0:\n",
    "    print(\"반복(Epoch): %d, Fine-tuning 손실 함수(finetuning_loss): %f\" % ((epoch + 1), finetuning_loss_print))\n",
    "print(\"Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\")\n",
    "\n",
    "# 오토인코더+Softmax 분류기 모델의 정확도를 출력합니다.\n",
    "print(\"정확도(오토인코더+Softmax 분류기): %f\" % compute_accuracy(SoftmaxClassifier_model(AutoEncoder_model(x_test)[1]), tf.one_hot(y_test, depth=10)))  # 정확도 : 약 96%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
